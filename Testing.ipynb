{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model, neighbors, svm, tree\n",
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "import time\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(f):\n",
    "    print(\"Accuracy = {0}%\".format(100*np.sum(f(X_test) == y_test)/len(y_test)))\n",
    "    time.sleep(0.5) # to let the print get out before any progress bars\n",
    "\n",
    "def gen_kfold(modelCV, X_train, y_train):\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    print(\"10-fold cross validation average accuracy: %.3f\" % (results.mean()))\n",
    "\n",
    "def gen_confusion(model, X_test): \n",
    "    y_pred = model.predict(X_test)\n",
    "    print('Accuracy of ' + model.__class__.__name__ + 'classifier on test set: {:.2f}'.format(model.score(X_test, y_test)))\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "logistic = linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, diagnosis, radius_mean, texture_mean, perimeter_mean, area_mean, smoothness_mean, compactness_mean, concavity_mean, concave points_mean, symmetry_mean, fractal_dimension_mean, radius_se, texture_se, perimeter_se, area_se, smoothness_se, compactness_se, concavity_se, concave points_se, symmetry_se, fractal_dimension_se, radius_worst, texture_worst, perimeter_worst, area_worst, smoothness_worst, compactness_worst, concavity_worst, concave points_worst, symmetry_worst, fractal_dimension_worst]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 32 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main = main.drop(\"Unnamed: 32\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BekkBlando/Documents/github/wisconsin_data/.direnv/python-3.6.5/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "main.ix[main.diagnosis == 'M', 'diagnosis'] = 1\n",
    "main.ix[main.diagnosis == 'B', 'diagnosis'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = main.columns.values.tolist()\n",
    "y = ['diagnosis']\n",
    "exclude = ['diagnosis', 'id']\n",
    "X = [col for col in final_cols if col not in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BekkBlando/Documents/github/wisconsin_data/.direnv/python-3.6.5/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(logistic, 18)\n",
    "rfe = rfe.fit(main[X], main[y] )\n",
    "col_order = rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for index, col in enumerate(X) if col_order[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = main[cols]\n",
    "y = main['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "from sklearn import metrics\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegressionclassifier on test set: 0.94\n",
      "[[101   7]\n",
      " [  4  59]]\n",
      "10-fold cross validation average accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "gen_confusion(logreg, X_test)\n",
    "gen_kfold(linear_model.LogisticRegression(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 95.32163742690058%\n",
      "Accuracy of KNeighborsClassifierclassifier on test set: 0.95\n",
      "[[103   5]\n",
      " [  3  60]]\n",
      "10-fold cross validation average accuracy: 0.932\n"
     ]
    }
   ],
   "source": [
    "# Time for K Means\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print_accuracy(knn.predict)\n",
    "\n",
    "gen_confusion(knn, X_test)\n",
    "gen_kfold(neighbors.KNeighborsClassifier(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 90.64327485380117%\n",
      "Accuracy of SVCclassifier on test set: 0.91\n",
      "[[93 15]\n",
      " [ 1 62]]\n",
      "10-fold cross validation average accuracy: 0.876\n"
     ]
    }
   ],
   "source": [
    "# SVM Time - Radial Kernal\n",
    "svc_radial = svm.SVC(kernel='rbf', probability=True)\n",
    "svc_radial.fit(X_train, y_train)\n",
    "print_accuracy(svc_radial.predict)\n",
    "\n",
    "gen_confusion(svc_radial, X_test)\n",
    "gen_kfold(svm.SVC(kernel='rbf', probability=True), X_train, y_train)\n",
    "\n",
    "# TODO Generate these graphs\n",
    "# shap_values = shap.KernelExplainer(svc_radial.predict_proba, X_train).shap_values(X_test)\n",
    "# shap.force_plot(shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 63.1578947368421%\n",
      "Accuracy of SVCclassifier on test set: 0.63\n",
      "[[108   0]\n",
      " [ 63   0]]\n",
      "10-fold cross validation average accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "# SVM Time - Sigmoid Kernal\n",
    "svc_sigmoid = svm.SVC(kernel='sigmoid', probability=True)\n",
    "svc_sigmoid.fit(X_train, y_train)\n",
    "print_accuracy(svc_sigmoid.predict)\n",
    "\n",
    "gen_confusion(svc_sigmoid, X_test)\n",
    "gen_kfold(svm.SVC(kernel='sigmoid', probability=True), X_train, y_train)\n",
    "\n",
    "# TODO Generate these graphs\n",
    "# shap_values = shap.KernelExplainer(svc_sigmoid.predict_proba, X_train).shap_values(X_test)\n",
    "# shap.force_plot(shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 92.98245614035088%\n",
      "Accuracy of SVCclassifier on test set: 0.93\n",
      "[[98 10]\n",
      " [ 2 61]]\n",
      "10-fold cross validation average accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "# SVM Time - Polynomial Kernal\n",
    "svc_poly = svm.SVC(kernel='poly', probability=True)\n",
    "svc_poly.fit(X_train, y_train)\n",
    "print_accuracy(svc_poly.predict)\n",
    "\n",
    "gen_confusion(svc_poly, X_test)\n",
    "gen_kfold(svm.SVC(kernel='poly', probability=True), X_train, y_train)\n",
    "\n",
    "# TODO Generate these graphs\n",
    "# shap_values = shap.KernelExplainer(svc_linear.predict_proba, X_train).shap_values(X_test)\n",
    "# shap.force_plot(shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 95.90643274853801%\n",
      "Accuracy of SVCclassifier on test set: 0.96\n",
      "[[102   6]\n",
      " [  1  62]]\n",
      "10-fold cross validation average accuracy: 0.945\n"
     ]
    }
   ],
   "source": [
    "# SVM Time - Linear Kernal\n",
    "svc_linear = svm.SVC(kernel='linear', probability=True)\n",
    "svc_linear.fit(X_train, y_train)\n",
    "print_accuracy(svc_linear.predict)\n",
    "\n",
    "\n",
    "gen_confusion(svc_linear, X_test)\n",
    "gen_kfold(svm.SVC(kernel='linear', probability=True), X_train, y_train)\n",
    "\n",
    "# TODO Generate these graphs\n",
    "# shap_values = shap.KernelExplainer(svc_linear.predict_proba, X_train).shap_values(X_test)\n",
    "# shap.force_plot(shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 94.73684210526316%\n",
      "Accuracy of RandomForestClassifierclassifier on test set: 0.95\n",
      "[[103   5]\n",
      " [  4  59]]\n",
      "10-fold cross validation average accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rforest = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=0)\n",
    "rforest.fit(X_train, y_train)\n",
    "print_accuracy(rforest.predict)\n",
    "\n",
    "gen_confusion(rforest, X_test)\n",
    "gen_kfold(RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=0), X_train, y_train)\n",
    "\n",
    "# TODO Generate these graphs\n",
    "# shap_values = shap.KernelExplainer(rforest.predict_proba, X_train).shap_values(X_test)\n",
    "# shap.force_plot(shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 92.39766081871345%\n",
      "Accuracy of DecisionTreeClassifierclassifier on test set: 0.92\n",
      "[[98 10]\n",
      " [ 3 60]]\n",
      "10-fold cross validation average accuracy: 0.917\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Time\n",
    "dtree = tree.DecisionTreeClassifier(min_samples_split=2)\n",
    "dtree.fit(X_train, y_train)\n",
    "print_accuracy(dtree.predict)\n",
    "\n",
    "gen_confusion(dtree, X_test)\n",
    "gen_kfold(tree.DecisionTreeClassifier(min_samples_split=2), X_train, y_train)\n",
    "\n",
    "\n",
    "# TODO Generate these graphs\n",
    "# shap_values = shap.KernelExplainer(dtree.predict_proba, X_train).shap_values(X_test)\n",
    "# shap.force_plot(shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 92.98245614035088%\n",
      "Accuracy of MLPClassifierclassifier on test set: 0.93\n",
      "[[99  9]\n",
      " [ 3 60]]\n",
      "10-fold cross validation average accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "# Simple Neural Net\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier(solver='lbfgs', alpha=1e-1, hidden_layer_sizes=(5, 2), random_state=0)\n",
    "nn.fit(X_train, y_train)\n",
    "print_accuracy(nn.predict)\n",
    "\n",
    "gen_confusion(nn, X_test)\n",
    "gen_kfold(MLPClassifier(solver='lbfgs', alpha=1e-1, hidden_layer_sizes=(5, 2), random_state=0), X_train, y_train)\n",
    "\n",
    "# explain all the predictions in the test set\n",
    "# shap_values = shap.KernelExplainer(nn.predict_proba, X_train).shap_values(X_test)\n",
    "# shap.force_plot(shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 91.2280701754386%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/171 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GaussianNBclassifier on test set: 0.91\n",
      "[[101   7]\n",
      " [  8  55]]\n",
      "10-fold cross validation average accuracy: 0.942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|          | 2/171 [01:27<2:03:42, 43.92s/it]"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print_accuracy(gnb.predict)\n",
    "\n",
    "gen_confusion(gnb, X_test)\n",
    "gen_kfold(GaussianNB(), X_train, y_train)\n",
    "shap_values = shap.KernelExplainer(gnb.predict_proba, X_train).shap_values(X_test)\n",
    "shap.force_plot(shap_values[0], X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85.38011695906432%\n",
      "Accuracy of SGDClassifierclassifier on test set: 0.85\n",
      "[[103   5]\n",
      " [ 20  43]]\n",
      "10-fold cross validation average accuracy: 0.836\n"
     ]
    }
   ],
   "source": [
    "# SGD Classifier\n",
    "clf = linear_model.SGDClassifier(max_iter=30, tol=1e-3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print_accuracy(clf.predict)\n",
    "\n",
    "gen_confusion(clf, X_test)\n",
    "gen_kfold(linear_model.SGDClassifier(max_iter=100, tol=1e-3), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 84.21052631578948%\n",
      "Accuracy of SGDClassifierclassifier on test set: 0.84\n",
      "[[91 17]\n",
      " [10 53]]\n",
      "10-fold cross validation average accuracy: 0.737\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "probability estimates are not available for loss='perceptron'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-0b0d54c86cbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgen_kfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"perceptron\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"constant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKernelExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/wisconsin_data/.direnv/python-3.6.5/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mhttp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mjmlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medu\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpapers\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvolume2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mzhang02c\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mzhang02c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         \"\"\"\n\u001b[0;32m--> 834\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/github/wisconsin_data/.direnv/python-3.6.5/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_check_proba\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"modified_huber\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             raise AttributeError(\"probability estimates are not available for\"\n\u001b[0;32m--> 796\u001b[0;31m                                  \" loss=%r\" % self.loss)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: probability estimates are not available for loss='perceptron'"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "iteration = 10\n",
    "clf = linear_model.SGDClassifier(loss=\"perceptron\", eta0=1, learning_rate=\"constant\", penalty=None, max_iter=iteration, tol=1e-3)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print_accuracy(clf.predict)\n",
    "\n",
    "gen_confusion(clf, X_test)\n",
    "gen_kfold(linear_model.SGDClassifier(loss=\"perceptron\", eta0=1, learning_rate=\"constant\", penalty=None, max_iter=iteration, tol=1e-3), X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
